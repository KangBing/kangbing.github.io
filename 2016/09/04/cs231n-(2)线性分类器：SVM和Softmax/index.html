<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>cs231n-(2)线性分类器：SVM和Softmax | KangBing&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="概述上节讲到了图像分类以及kNN算法，kNN用作图像分类效果并不好。效果更好的分类算法是神经网络和卷积神经网络，它主要包括2部分1、评分函数score function，把原数据映射为一个得分。2、损失函数loss function，衡量预测得分和真实标签之间的差距。最终的优化问题是最小化损失函数。">
<meta property="og:type" content="article">
<meta property="og:title" content="cs231n-(2)线性分类器：SVM和Softmax">
<meta property="og:url" content="http://kangbing.github.io/2016/09/04/cs231n-(2)线性分类器：SVM和Softmax/index.html">
<meta property="og:site_name" content="KangBing's Blog">
<meta property="og:description" content="概述上节讲到了图像分类以及kNN算法，kNN用作图像分类效果并不好。效果更好的分类算法是神经网络和卷积神经网络，它主要包括2部分1、评分函数score function，把原数据映射为一个得分。2、损失函数loss function，衡量预测得分和真实标签之间的差距。最终的优化问题是最小化损失函数。">
<meta property="og:image" content="https://raw.githubusercontent.com/KangBing/blog-img/master/blog/cs231n2_01.jpeg">
<meta property="og:image" content="https://raw.githubusercontent.com/KangBing/blog-img/master/blog/cs231n2_02.jpeg">
<meta property="og:image" content="https://raw.githubusercontent.com/KangBing/blog-img/master/blog/cs231n2_03.jpeg">
<meta property="og:image" content="https://raw.githubusercontent.com/KangBing/blog-img/master/blog/cs231n2_04.jpeg">
<meta property="og:image" content="https://raw.githubusercontent.com/KangBing/blog-img/master/blog/cs231n2_05.jpeg">
<meta property="og:image" content="https://raw.githubusercontent.com/KangBing/blog-img/master/blog/cs231n2_06.jpeg">
<meta property="og:updated_time" content="2018-12-19T15:27:14.368Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="cs231n-(2)线性分类器：SVM和Softmax">
<meta name="twitter:description" content="概述上节讲到了图像分类以及kNN算法，kNN用作图像分类效果并不好。效果更好的分类算法是神经网络和卷积神经网络，它主要包括2部分1、评分函数score function，把原数据映射为一个得分。2、损失函数loss function，衡量预测得分和真实标签之间的差距。最终的优化问题是最小化损失函数。">
  
    <link rel="alternative" href="/atom.xml" title="KangBing&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
      <link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css" type="text/css">
  
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  
  
      <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  
  <script>
      var yiliaConfig = {
          fancybox: true,
          animate: true,
          isHome: false,
          isPost: true,
          isArchive: false,
          isTag: false,
          isCategory: false,
          open_in_new: false
      }
  </script>
  
      <script>
          var _hmt = _hmt || [];
          (function() {
              var hm = document.createElement("script");
              hm.src = "//hm.baidu.com/hm.js?1ad2f92496bbe7f551683e065f125883";
              var s = document.getElementsByTagName("script")[0]; 
              s.parentNode.insertBefore(hm, s);
          })();
      </script>
  
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            
            <img lazy-src="/img/avatar.png" class="js-avatar">
            
        </a>

        <hgroup>
          <h1 class="header-author"><a href="/">KangBing</a></h1>
        </hgroup>

        
        <p class="header-subtitle">A Championship Heart!</p>
        
                


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">分类和标签</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <li id="Email"><a class="Email" target="_blank" href="mailto:kangyabing@126.com" title="Email"></a></li>
                            
                                <li id="GitHub"><a class="GitHub" target="_blank" href="/#" title="GitHub"></a></li>
                            
                                <li id="RSS"><a class="RSS" target="_blank" href="/atom.xml" title="RSS"></a></li>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <a href="/tags/AutoDiff/" style="font-size: 10px;">AutoDiff</a> <a href="/tags/BatchNorm/" style="font-size: 10px;">BatchNorm</a> <a href="/tags/DeepLearning/" style="font-size: 20px;">DeepLearning</a> <a href="/tags/Depthwise/" style="font-size: 10px;">Depthwise</a> <a href="/tags/Ensembles/" style="font-size: 10px;">Ensembles</a> <a href="/tags/Inception/" style="font-size: 12.5px;">Inception</a> <a href="/tags/Inception-V3/" style="font-size: 10px;">Inception-V3</a> <a href="/tags/Inception-V4/" style="font-size: 10px;">Inception-V4</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/ParameterServer/" style="font-size: 10px;">ParameterServer</a> <a href="/tags/Protocol-BUffers/" style="font-size: 10px;">Protocol BUffers</a> <a href="/tags/R-CNN/" style="font-size: 10px;">R-CNN</a> <a href="/tags/Residual/" style="font-size: 12.5px;">Residual</a> <a href="/tags/SGD/" style="font-size: 10px;">SGD</a> <a href="/tags/SPP-net/" style="font-size: 10px;">SPP-net</a> <a href="/tags/Xavier/" style="font-size: 10px;">Xavier</a> <a href="/tags/Xception/" style="font-size: 10px;">Xception</a> <a href="/tags/backforward/" style="font-size: 10px;">backforward</a> <a href="/tags/c/" style="font-size: 10px;">c++</a> <a href="/tags/cs231n/" style="font-size: 17.5px;">cs231n</a> <a href="/tags/feature/" style="font-size: 10px;">feature</a> <a href="/tags/glog/" style="font-size: 10px;">glog</a> <a href="/tags/google/" style="font-size: 12.5px;">google</a> <a href="/tags/kNN/" style="font-size: 10px;">kNN</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/softmax/" style="font-size: 10px;">softmax</a> <a href="/tags/数值计算/" style="font-size: 10px;">数值计算</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/概率/" style="font-size: 10px;">概率</a> <a href="/tags/神经网络/" style="font-size: 15px;">神经网络</a> <a href="/tags/线性代数/" style="font-size: 10px;">线性代数</a>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a target="_blank" class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a target="_blank" class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a target="_blank" class="main-nav-link switch-friends-link" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">专注写代码</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">KangBing</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                
                    <img lazy-src="/img/avatar.png" class="js-avatar">
                
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">KangBing</a></h1>
            </hgroup>
            
            <p class="header-subtitle">A Championship Heart!</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">分类和标签</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <li id="Email"><a class="Email" target="_blank" href="mailto:kangyabing@126.com" title="Email"></a></li>
                            
                                <li id="GitHub"><a class="GitHub" target="_blank" href="/#" title="GitHub"></a></li>
                            
                                <li id="RSS"><a class="RSS" target="_blank" href="/atom.xml" title="RSS"></a></li>
                            
                        </ul>
            </nav>
        </header>                
    </div>
</nav>
      <div class="body-wrap"><article id="post-cs231n-(2)线性分类器：SVM和Softmax" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/09/04/cs231n-(2)线性分类器：SVM和Softmax/" class="article-date">
      <time datetime="2016-09-04T14:25:55.000Z" itemprop="datePublished">2016-09-04</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs231n-(2)线性分类器：SVM和Softmax
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/cs231n笔记/">cs231n笔记</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepLearning/">DeepLearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cs231n/">cs231n</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/softmax/">softmax</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p><strong>概述</strong><br>上节讲到了图像分类以及kNN算法，kNN用作图像分类效果并不好。效果更好的分类算法是神经网络和卷积神经网络，它主要包括2部分<br>1、评分函数score function，把原数据映射为一个得分。<br>2、损失函数loss function，衡量预测得分和真实标签之间的差距。<br>最终的优化问题是最小化损失函数。</p>
<ul>
<li><a id="more"></a>
</li>
</ul>
<h2 id="图像到标签得分的参数映射">图像到标签得分的参数映射</h2><p>首先定义图像像素数据到各个类别得分的映射。定义几个符号，训练集为$x_i \in R^D$，训练集的每个元素有个对应的标签$y_i$，$i=1 \dots N$，$y_i \in 1 \dots K$。即训练集有$N$个数据，维度为$D$，每个训练数据对应一个标签$y_i$，标签总共有$K$类。以CIFAR-10为例，$N=50,000, D=32 \times 32 \times 3 =3072, K=10$。定义评分函数$f: R^D \mapsto R^K$</p>
<h3 id="线性分类器"><strong>线性分类器</strong></h3><p>一个常用的映射函数为<br>$$<br>f(x_i,W,b)=Wx_i+b<br>$$<br>$x_i$是图像数据，展开为一个列向量[D x 1]。矩阵<strong>$W$</strong>（维度[K x D]）和向量<strong>$b$</strong>（维度[K x1])是函数的参数，分为被称为权重和偏置。<br>需要注意：<br>1、$Wx_i$得到的乘积是个列向量[K x 1]，K个值对应K类。<br>2、优化的目的就是让上面函数的得分尽量和真实标签的值接近。<br>3、训练结束后，可以丢弃训练数据，只使用学到的参数值即可预测。<br>4、预测时只是矩阵的相乘和相加，速度很快。</p>
<p>解释线性分类器：<br>线性分类器是计算图像所有像素值的加权和，图像包括3个颜色通道。根据我们队权重（正/负）的设置，映射函数可以喜好或讨厌某一类颜色。例如，对于“船”这个类别，蓝色（海水）可能会在图像占比较大比例。这样在分类“船”时，蓝色对应的通道的可能会有比较多的正权重，而红色和绿色通道可能会有比较多的负权重。<br>下面是一个图像分的例子：<br><img src="https://raw.githubusercontent.com/KangBing/blog-img/master/blog/cs231n2_01.jpeg" alt="cs231n2_01.jpeg"><br>可以看出，更加倾向认为是一只狗。</p>
<h3 id="类比高维空间"><strong>类比高维空间</strong></h3><p>图像被展开为高维空间的列向量，可以把图像当做高维空间的一个点（例如CIFAR-10的中图像是3072维度空间的一个点）。线性分类函数就是来划分这个高维空间，假设这个高维空间是2维的，可视化后如下:<br><img src="https://raw.githubusercontent.com/KangBing/blog-img/master/blog/cs231n2_02.jpeg" alt="cs231n_02.jpeg"><br>上图表示图像空间，每个点都是一个图像。矩阵$W$的每一行都是一条直线，控制其方向，$b$控制平移，直线上的点对应的得分为0，</p>
<h3 id="线性分类器看做模板匹配"><strong>线性分类器看做模板匹配</strong></h3><p>权重矩阵<strong>$W$</strong>的每一行可以看做匹配某一类的模板，每一类的打分就是图像和对应类别模板的乘积。下图是CIFAR-10训练后的模板的可视化图像：<br><img src="https://raw.githubusercontent.com/KangBing/blog-img/master/blog/cs231n2_03.jpeg" alt="cs231n_3.jpeg"><br>可以看出“船”的模板包含很多蓝色的像素，这样会给蓝色通道像素分值比较高。</p>
<h3 id="偏置技巧"><strong>偏置技巧</strong></h3><p>可以把上面公式中，后面加的权重放到前面的矩阵乘法中，技巧就拓展矩阵多出一列，输入数据多出一维，最终公式变为：<br>$$<br>f(x_i,W)=Wx_i<br>$$<br>通过下图一看便知<br><img src="https://raw.githubusercontent.com/KangBing/blog-img/master/blog/cs231n2_04.jpeg" alt="cs231n2_04.jpeg"></p>
<h3 id="数据预处理">数据预处理</h3><p>图像的像素范围是[0…255]，但是在机器学习中经常要将特征归一化。经常用到的是把数据<strong>中心化center your data</strong>，通过减去每个特征的均值来做到的。例如减去像素的均值，可以是范围变为[-127…127]。有时还做进一步处理，使范围变为[-1,1]。0均值中心化非常重要，学了梯度下降就可以理解这一点了。</p>
<h2 id="损失函数">损失函数</h2><p>前面通过评分函数来计算属于每一类的得分。这里通过<strong>损失函数</strong>来计算对得分的满意程度。损失函数又称作<strong>代价函数</strong>或<strong>目标</strong>。结果越好，损失函数值将越低，结果越差，损失函数的值将越高。</p>
<h3 id="多类SVM_loss">多类SVM loss</h3><p>这里定义SVM的loss函数。SVM loss会使正确类别的得分比错误类别的得分至少高$\Delta$。用$s$代表分数，第i个图像对应第j类的得分$s_j=f(x_i,W)_j$，那么多类别SVM对于第i个图像的loss为<br>$$<br>L_i=\sum_{j \neq y_i}max(0, s_j-s_{y_i} + \Delta)<br>$$<br><strong>一个例子</strong><br>假设有3个类别，对应的得分<strong>$s=[13, -7, 11]$</strong>，真实类别是<strong>$y_i=0$</strong>，$\Delta=10$。损失函数有2项<br>$$<br>L_i = max(0, -7 - 13 + 10) + max(0, 11 - 13 + 10)<br>$$<br>上式中第一项为0，因为-7分值和真实得分相差20，大于$\Delta$；，第二项就不为0了，因为11分值和13只相差2，所以Loss函数就不为0了。<br>这一节是将线性分类器，所以Loss函数有以下形式<br>$$<br>L_i = \sum_{j\neq y_i} \max(0, w_j^T x_i - w_{y_i}^T x_i + \Delta)<br>$$<br>下图就是多类别SVM loss可视化图。<br><img src="https://raw.githubusercontent.com/KangBing/blog-img/master/blog/cs231n2_05.jpeg" alt="cs231n_05.jepg"><br>上面损失函数有叫做<strong>hinge loss</strong>，形式为$max(0,-)$，有时会使square hinge loss（或L2-SVM）来代替，形式为$max(0,-)^2$。</p>
<h3 id="正则化"><strong>正则化</strong></h3><p>上面提到的loss函数有bug。设想以下，假设假设评价函数能正确预测所有分类，且损失函数<strong>$L_i=0$</strong>；这样权重并不是唯一的。因为如果一组权重<strong>$W$</strong>符合这样的要求，那么<strong>$\lambda W$</strong>也符合这样的要求($\lambda &gt;1$。如果得到评价函数的值不为0，那么评价函数的值也会放大$\lambda$倍。</p>
<p>可以通过对<strong>$W$</strong>加上些限制来移除上面的不确定性，得到一个唯一确定的权重系数矩阵。一般是通过正则化惩罚来实现<strong>$R(W)$</strong>来实现。最常用的惩罚是 <strong>$L2$</strong> 范数：<br>$$<br>R(W)=\sum_k \sum_l W_{k,l}^2<br>$$<br>这个公式中不包含数据，是和数据无关的的loss。这样<strong>$L_i$</strong>就由2项组成了:<strong>data loss</strong>，<strong>regularization loss</strong>。<br>$$<br>L =  \underbrace{ \frac{1}{N} \sum_i L_i }_\text{data loss} + \underbrace{ \lambda R(W) }_\text{regularization loss} \\<br>$$<br>展开后形式如下:<br>$$<br>L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + \Delta) \right] + \lambda \sum_k\sum_l W_{k,l}^2<br>$$<br>上式中<strong>$\lambda$</strong>是一个超参数，通过使用交叉验证来设置它。</p>
<p>引入正则化惩罚还可以带来其他许多性质，后面章节会提到。例如，在SVM中引入正则化后就有了<strong>最大间隔max margin</strong>这一性质，详细参考<a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="external">cs229</a>。</p>
<p>正则化一个很好的性质是惩罚了大的权重值，这一可以提高模型泛化能力。限制权重大小后，没有那一维数据可能单独对评价函数带来很大影响。例如输入数据<strong>$x=[1,1,1,1,1]$</strong>，有两组权重<strong>$w_1=[1,0,0,0], w_2=[0.25,0.25,0.25,0.25]$</strong>，内积相等<strong>$w_1^Tx=w_2^Tx=1$</strong>。但是L2惩罚不同，对于<strong>$w_1$</strong>是1.0，而对于<strong>$w_2$</strong>是0.25,因此<strong>$w_2$</strong>优于<strong>$w_1$</strong>。直观上看，<strong>$w_2$</strong>更小，却值更加分散，这样输入数据的所有维度都会对评价函数有影响，而不是仅仅几个维度数据主要决定评价函数。因此，会有更好的泛化性能，减小过拟合。</p>
<p>需要注意，正则化只是针对权重<strong>$W$</strong>，而不针对偏差<strong>$b$</strong>，因为偏差对输入数据各个维度大小没有影响影响，它只是控制分类器的平移。</p>
<h3 id="实践注意事项">实践注意事项</h3><p><strong>设置$\Delta$</strong>：$\Delta$这个超参数一个常用的值是$\Delta = 1.0$。超参数$\Delta$和$\lambda$看上去是不同的超参数，实际上它们有同样的功能：平衡目标函数中的data loss和regularization loss。权重<strong>$W$</strong>的幅度直接影响评价函数的得分，例如放大权重幅度，得分也会变大，不同类别之间的得分差异也就变大了。$\Delta$是控制不同类别之间的得分差异，其他小可以通过放大或缩小权重幅度来控制。实际上权重的平衡是允许幅度有多大变化（通过$\lambda$来控制）。</p>
<p><strong>和二项SVM关系</strong>：二项SVM是多项SVM的一个特例。</p>
<p><strong>在原始形式中优化</strong>：如果以前学过SVMs，可能会听过核方法、对偶、SMO算法等。在神经网络中，往往使用目标函数的原始形式。许多模板函数在技术上不可分，但是实际中可以使用次梯度。</p>
<p><strong>其他形式的SVM</strong>：本节的多类SVM只是一种，还有其他形式。</p>
<h2 id="Softmax分类器">Softmax分类器</h2><p>除了SVM分类器外，还有一种常用的叫做<strong>Softmax分类器</strong>，它是二元逻辑回归泛化到多元的情况。Softmax分类器的输出不是得分，而是对应类别的概率。Softmax分类器中，映射函数<strong>$f(x_i; W) =  W x_i$</strong>并没改变，把得分当做未归一化的对数概率，把hinge loss替换为<strong>交叉熵</strong> loss:<br>$$<br>L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right) \hspace{0.5in} \text{or equivalently} \hspace{0.5in} L_i = -f_{y_i} + \log\sum_j e^{f_j}<br>$$<br>其中,<strong>$f_j$</strong>表示第j类的得分。整个数据集的loss是<strong>$L_i$</strong>加上正则化项<strong>$R(W)$</strong>。函数<strong>$f_j(z) = \frac{e^{z_j}}{\sum_k e^{z_k}}$</strong>叫做<strong>softmax函数</strong>，它把得分向量转换为概率向量。</p>
<p><strong>信息论角度</strong>：一个真实分布<strong>$p$</strong>和气估计分布<strong>$q$</strong>的交叉熵定义如下：<br>$$<br>H(p,q)=-\sum_xp(x) \log q(x)<br>$$<br>Softmax分类器是最小化估计的分布（$q = e^{f_{y_i}}  / \sum_j e^{f_j}$）和真实分布（$p=[0,…,1,…,0]$，只有第$y<em>i$个为1）之间交叉熵。交叉熵可以看做熵和相对熵的和相对熵的和**$H(p,q) = H(p) + D</em>{KL}(p||q)$<strong>，真实分布</strong>$p$**的熵是零，所以最小化交叉熵等价于最小化相对熵。</p>
<p><strong>概率解释</strong>：公式<br>
$$
P(y_i \mid x_i; W) = \frac{e^{f_{y_i}}}{\sum_j e^{f_j} }
$$
<br>已知输入数据<strong>$x_i$</strong>和权重参数<strong>$W$</strong>，上式可以看做对应类别<strong>$y_i$</strong>的归一化概率。评价函数的输出向量没有归一化，直接当做对数概率的输入，之后用对数概率除以所有概率的和来进行归一化，这样概率的和为1。从概率论角度看，我们再最小化正确分类的负概率（即最大化正确分类的概率），这是最大似然估计（Maximum Likelihood Estimation）。这样损失函数中的正则化部分<strong>$R(W)$</strong>可以看过权重矩阵<strong>$W$</strong>的高斯先验，这样最大似然估计变成了最大后验概率估计（Maximum a posteriori）。</p>
<p><strong>实践问题：数值稳定</strong>：当写代码实现Softmax函数时，会涉及到<strong>$e^{f_{y_i}}$</strong>和<strong>$\sum_j e^{f_j}$</strong>，因为指数的原因，这些数值可能会非常大。除以很大的数值可能会引起数值不稳定，可以使用归一化的技巧。在分子和分母同时乘以一个常数，分数的数值不变：<br>$$<br>\frac{e^{f_{y_i}}}{\sum_j e^{f_j}}<br>= \frac{Ce^{f_{y_i}}}{C\sum_j e^{f_j}}<br>= \frac{e^{f_{y_i} + \log C}}{\sum_j e^{f_j + \log C}}<br>$$<br><strong>$C$</strong>通常设为<strong>$\log C = -\max x_if_j$</strong>，这样分数向量中最大的值为0。</p>
<h2 id="SVM_vs-_Softmax">SVM vs. Softmax</h2><p>下面图像可以帮助对比两者区别<br><img src="https://raw.githubusercontent.com/KangBing/blog-img/master/blog/cs231n2_06.jpeg" alt="cs231n2_06.jpeg"></p>
<p><strong>Softmax分类器计算每类的概率</strong>：SVM计算每类的得分，这样不易直接解释。Softmax计算每类的概率。超参数<strong>$\lambda$</strong>控制概率的集中或离散程度。</p>
<p><strong>实践中，SVM和Softmax常常是相似的</strong>：SVM和Softmax性能差别不大，不同的人对哪种效果更好持不同的观点。和Softmax相比，SVM更加局部化（local objective），它只关心小于间隔$\Delta$的部分，例如$\Delta = 1$，那么分值[10, -100, -100]和[10, 9, 9]对于SVM来说，其loss函数值相同；但是对于softmax就不同了。Softmax的loss函数只有在完全正确情况下才会为0。</p>
<h2 id="总结">总结</h2><p>1、定义了评价函数，线性函数的评价函数依赖权重<strong>$W$</strong>和偏置<strong>$b$</strong>。<br>2、和kNN使用不一样，参数化方法训练时间比较久，预测只是矩阵相乘。<br>3、通过一个trick，可以把偏置加入到矩阵相乘中。<br>4、定义了loss 函数，介绍了常用的SVM和Softmax loss。对比了两者的区别。</p>
<p>如果求解最优的参数，这设计到<em>优化</em>，是下一节讲解的问题。</p>
<h2 id="拓展阅读">拓展阅读</h2><p><a href="http://arxiv.org/abs/1306.0239" target="_blank" rel="external">Deep Learning using Linear Support Vector Machines</a></p>

      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2016/09/04/cs231n-(2)线性分类器：SVM和Softmax/">cs231n-(2)线性分类器：SVM和Softmax</a></p>
        <p><span>文章作者:</span><a href="/" title="访问 KangBing 的个人博客">KangBing</a></p>
        <p><span>发布时间:</span>2016年09月04日 - 22时25分</p>
        <p><span>最后更新:</span>2018年12月19日 - 23时27分</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2016/09/04/cs231n-(2)线性分类器：SVM和Softmax/" title="cs231n-(2)线性分类器：SVM和Softmax">http://kangbing.github.io/2016/09/04/cs231n-(2)线性分类器：SVM和Softmax/</a>
            <span class="copy-path" data-clipboard-text="原文: http://kangbing.github.io/2016/09/04/cs231n-(2)线性分类器：SVM和Softmax/　　作者: KangBing" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script src="/js/clipboard.min.js"></script>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" title="中国大陆 (CC BY-NC-SA 3.0 CN)" target = "_blank">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



    <nav id="article-nav">
        
            <div id="article-nav-newer" class="article-nav-title">
                <a href="/2016/09/04/cs231n-(3)最优化：随机梯度下降/">
                    cs231n-(3)最优化：随机梯度下降
                </a>
            </div>
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2016/09/04/cs231n-(1)图像分类和kNN/">
                    cs231n-(1)图像分类和kNN
                </a>
            </div>
        
    </nav>

  
</article>

    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#图像到标签得分的参数映射"><span class="toc-number">1.</span> <span class="toc-text">图像到标签得分的参数映射</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#线性分类器"><span class="toc-number">1.1.</span> <span class="toc-text">线性分类器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#类比高维空间"><span class="toc-number">1.2.</span> <span class="toc-text">类比高维空间</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#线性分类器看做模板匹配"><span class="toc-number">1.3.</span> <span class="toc-text">线性分类器看做模板匹配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#偏置技巧"><span class="toc-number">1.4.</span> <span class="toc-text">偏置技巧</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据预处理"><span class="toc-number">1.5.</span> <span class="toc-text">数据预处理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#损失函数"><span class="toc-number">2.</span> <span class="toc-text">损失函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#多类SVM_loss"><span class="toc-number">2.1.</span> <span class="toc-text">多类SVM loss</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#正则化"><span class="toc-number">2.2.</span> <span class="toc-text">正则化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#实践注意事项"><span class="toc-number">2.3.</span> <span class="toc-text">实践注意事项</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Softmax分类器"><span class="toc-number">3.</span> <span class="toc-text">Softmax分类器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SVM_vs-_Softmax"><span class="toc-number">4.</span> <span class="toc-text">SVM vs. Softmax</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">5.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#拓展阅读"><span class="toc-number">6.</span> <span class="toc-text">拓展阅读</span></a></li></ol>
</div>
<style>
    .left-col .switch-btn {
        display: none;
    }
    .left-col .switch-area {
        display: none;
    }
</style>

<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script>
    var valueHide = "隐藏目录";
    var valueShow = "显示目录";

    if ($(".left-col").is(":hidden")) {
        $("#tocButton").attr("value", valueShow);
    }

    $("#tocButton").click(function() {
        if ($("#toc").is(":hidden")) {
            $("#tocButton").attr("value", valueHide);
            $("#toc").slideDown(320);
            $(".switch-btn, .switch-area").fadeOut(300);
        }
        else {
            $("#tocButton").attr("value", valueShow);
            $("#toc").slideUp(350);
            $(".switch-btn, .switch-area").fadeIn(500);
        }
    })

    if ($(".toc").length < 1) {
        $("#toc, #tocButton").hide();
        $(".switch-btn, .switch-area").show();
    }
</script>




    <div class="share">
    <div class="bdsharebuttonbox">
    <a href="#" class="bds_more" data-cmd="more"></a>
    <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
    <a href="#" class="bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
    <a href="#" class="bds_copy" data-cmd="copy" title="复制网址"></a>
    <a href="#" class="bds_mail" data-cmd="mail" title="通过邮件分享"></a>
    <a href="#" class="bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
    </div>
    <script>
        window._bd_share_config={
            "common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
    </script>
</div>



    
        <section class="youyan" id="comments">
  <div id="uyan_frame"></div>
  <script src="http://v2.uyan.cc/code/uyan.js?uid=2136539"></script>
</section>

    




    <div class="scroll" id="post-nav-button">
        
            <a href="/2016/09/04/cs231n-(3)最优化：随机梯度下降/" title="上一篇: cs231n-(3)最优化：随机梯度下降">
                <i class="fa fa-angle-left"></i>
            </a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2016/09/04/cs231n-(1)图像分类和kNN/" title="下一篇: cs231n-(1)图像分类和kNN">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/12/28/C++/C++11中的内存模型/">C++11中的内存模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/04/MXNet/自动微分/">自动微分</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/25/MXNet/MXNet Data IO/">MXNet Data IO</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/14/MXNet/PS-Lite源码分析/">PS-Lite源码分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/26/Paper笔记/00010_Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition/">Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/24/Paper笔记/0009_Rich feature hierarchies for accurate object detection and semantic segmentation/">Rich feature hierarchies for accurate object detection and semantic segmentation</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/13/Paper笔记/0008_A Neural Algorithm of Artistic Style/">A Neural Algorithm of Artistic Style</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/09/Paper笔记/0007_Xception Deep Learning with Depthwise Separable Convolutios/">Xception--Deep Learning with Depthwise Separable Convolutios</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/06/Paper笔记/0006_Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning/">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/04/Paper笔记/0005_Rethinking the Inception Architecture for Computer Vision/">Rethinking the Inception Architecture for Computer Vision</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/31/Paper笔记/0004_Residual Networks Behave Like Ensembles of Relatively Shallow Networks/">Residual Networks Behave Like Ensembles of Relatively Shallow Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/14/Paper笔记/0003_Batch Normalization Accelerating Deep Network Training by Reducing Internal Covariate Shift/">Batch Normalization--Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/11/Paper笔记/0002_Understanding the difficulty of training deep feedforward neural networks/">Understanding the difficulty of training deep feedforward neural networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/22/Paper笔记/0001_ILSVRC历届冠军论文笔记/">ILSVRC历届冠军论文笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/18/cs231n-(9)迁移学习和Fine-tune网络/">cs231n-(9)迁移学习和Fine-tune网络</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/18/cs231n-(8)理解和可视化卷积网络/">cs231n-(8)理解和可视化卷积网络</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/18/cs231n-(7)卷积神经网络：架构，卷积层,池化层/">cs231n-(7)卷积神经网络：架构，卷积层/池化层</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/18/cs231n-(6)实现Minimal神经网络/">cs231n-(6)实现Minimal神经网络</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/03/Python实现三层神经网络/">Python实现三层神经网络</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/22/cs231n-(5)神经网络-3：学习和评估/">cs231n-(5)神经网络-3：学习和评估</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/24/cs231n-(5)神经网络-2：设置数据和Loss/">cs231n-(5)神经网络-2：设置数据和Loss</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/06/《Deep Learning》(4)-数值计算/">《Deep Learning》(4)-数值计算</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/06/《Deep Learning》(3)-概率和信息论/">《Deep Learning》(3)-概率和信息论</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/06/《Deep Learning》(2)-线性代数/">《Deep Learning》(2)-线性代数</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/06/《Deep Learning》(1)-介绍/">《Deep Learning》(1)-介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/06/cs231n-(5)神经网络-1：建立架构/">cs231n-(5)神经网络-1：建立架构</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/04/cs231n-(4)反向传播/">cs231n-(4)反向传播</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/04/cs231n-(3)最优化：随机梯度下降/">cs231n-(3)最优化：随机梯度下降</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/04/cs231n-(2)线性分类器：SVM和Softmax/">cs231n-(2)线性分类器：SVM和Softmax</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/04/cs231n-(1)图像分类和kNN/">cs231n-(1)图像分类和kNN</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/03/21/机器学习(7)-神经网络预测练习/">机器学习(7)-神经网络预测练习</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/03/15/机器学习(6)-神经网络/">机器学习(6)-神经网络</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/03/09/机器学习(5)-逻辑回归练习/">机器学习(5)-逻辑回归练习</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/03/07/机器学习(4)-正则化/">机器学习(4)-正则化</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/03/06/机器学习(3)-逻辑回归/">机器学习(3)-逻辑回归</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/02/29/机器学习(2)-线性回归/">机器学习(2)-线性回归</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/02/27/机器学习(1)-概念/">机器学习(1)-概念</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/01/18/Google-Logging-Library-glog-使用/">Google Logging Library(glog)使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/01/10/获取目录下的所有子目录和文件/">获取目录下的所有子目录和文件</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/12/21/Google Protocol BUffers使用/">Google Protocol BUffers使用</a></li></ul>
    <script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
    <script>
        $(".post-list").addClass("toc-article");
        $(".post-list-item a").attr("target","_blank");
        $("#post-nav-button > a:nth-child(2)").click(function() {
            $(".fa-bars, .fa-times").toggle();
            $(".post-list").toggle(300);
            if ($(".toc").length > 0) {
                $("#toc, #tocButton").toggle(200, function() {
                    if ($(".switch-area").is(":visible")) {
                        $("#toc, .switch-btn, .switch-area").toggle();
                        $("#tocButton").attr("value", valueHide);
                        }
                    })
            }
            else {
                $(".switch-btn, .switch-area").fadeToggle(300);
            }
        })
    </script>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                &copy; 2018 KangBing
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的静态博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减双栏 Hexo 博客主题">Yelee</a> by MOxFIVE
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" >本站到访数: 
                            <span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>, </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit">本页阅读量: 
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>




    <!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>
#add by kangyabing

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>

<script>
    $(document).ready(function() {
        if ($("#comments").length < 1) {
            $("#scroll > a:nth-child(2)").hide();
        };
    })
</script>


<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>

<!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
</body>
</html>